# The main entry point of your workflow.
SAMPLES = ['SRR4113427','SRR4113428','SRR4113429','SRR4113430','SRR4113431','SRR4113432','SRR4113433','SRR4113434','SRR4113435','SRR4113436','SRR4113437','SRR4113438','SRR4113438','SRR4113439','SRR4113440']
#SAMPLES = ['Test1','Test2']
REPLICONS = ['AL123456'] #Order of these affects the order they are printed.

with open("output/PREFIXES_FOR_CONVERSION.txt",'w') as fp:
    fp.write('\n'.join(['output/'+s for s in SAMPLES])) #Necessary for post processing wig files

# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.

#configfile: "config.yaml"
#report: "report/workflow.rst"

# Allow users to fix the underlying OS via singularity.
#singularity: "docker://continuumio/miniconda3"

rule all:
    input:
        expand("output/{sample}.wig", sample=SAMPLES),
        "output/Attenuated_Mutants_H37Rv.csv"

        # Subsequent target rules can be specified below. They should start with all_*.
#rule correct_SRA_headers

rule map_reads:
    conda:
        "envs/tpp_env.yml"
    input:
        "input/H37Rv.fa",
        "input/{sample}_1.fastq",
        "input/{sample}_2.fastq"
    output:
        "output/{sample}.wig"
    shell:
        #Compute bwa location to give to tpp
        "BWA=$(which bwa)\n"+
        "echo $BWA\n"+
        "tpp -himar1 -bwa $BWA -bwa-alg aln -ref {input[0]} -replicon-ids "+','.join(REPLICONS)+" -reads1 {input[1]} -reads2 {input[2]} -window-size 6 -primer AACCTGTTA -mismatches 1 -output output/{wildcards.sample}"

rule convert_to_csv:
    conda:
        "envs/tpp_env.yml"
    input:
        "input/H37Rv.gb",
        expand("output/{sample}.wig", sample=SAMPLES)
    output:
        "output/H37Rv_raw_counts.csv" 
    shell:
        "python2 scripts/wig_gb_to_csv.py -l output/PREFIXES_FOR_CONVERSION.txt -g {input[0]} -u locus_tag -f product regulatory_class bound_moiety -o {output}"

#Run find_lpi_sites_mtb.py
rule find_lpi_sites_mtb:
    conda:
        "envs/tpp_env.yml"
    input:
        "input/H37Rv.gb"
    output:
        "output/LPI_sites.csv"
    shell:
        "python2 scripts/find_lpi_sites_mtb.py"

rule run_tifa:
    conda:
        "envs/tifa.yml"
    input:
        "output/H37Rv_raw_counts.csv",
        "output/LPI_sites.csv"
    output:
        "output/Attenuated_Mutants_H37Rv.csv"
    shell:
        "python3 scripts/tifa_mtb.py"

#include: "rules/other.smk"
